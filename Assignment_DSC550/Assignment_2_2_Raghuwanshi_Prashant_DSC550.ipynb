{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d1a0055",
   "metadata": {},
   "source": [
    "### Assignment: 2.2 Exercise, Build Your Text Classifiers \n",
    "### Name: Prashant Raghuwanshi \n",
    "### Date: 9/10/2021\n",
    "### Course: DSC550-T301 Data Mining (2221-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90fd3015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import source file to data frame\n",
    "ccjsonsrc = pd.read_json('D:\\MS_DataScience\\DSC550\\controversial-comments.jsonl', lines = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41c282d",
   "metadata": {},
   "source": [
    "#### A. Convert all text to lowercase letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7080af4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>well it's great that he did something about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>you are right mr. president.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>you have given no input apart from saying i am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>i get the frustration but the reason they want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i am far from an expert on tpp and i would ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>0</td>\n",
       "      <td>&amp;gt; it's just too bad she sold her soul to fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>0</td>\n",
       "      <td>/globalists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0</td>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0</td>\n",
       "      <td>i can't disagree that machines will take many ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>0</td>\n",
       "      <td>i disagree. i think if child care were actuall...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      con                                                txt\n",
       "0       0  well it's great that he did something about th...\n",
       "1       0                       you are right mr. president.\n",
       "2       0  you have given no input apart from saying i am...\n",
       "3       0  i get the frustration but the reason they want...\n",
       "4       0  i am far from an expert on tpp and i would ten...\n",
       "...    ..                                                ...\n",
       "49995   0  &gt; it's just too bad she sold her soul to fo...\n",
       "49996   0                                        /globalists\n",
       "49997   0                                          [removed]\n",
       "49998   0  i can't disagree that machines will take many ...\n",
       "49999   0  i disagree. i think if child care were actuall...\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using lambda function and convert the string to lower case\n",
    "ccjsonlower = ccjsonsrc.apply(lambda x: x.astype(str).str.lower())\n",
    "# limitting the records in dataframe\n",
    "sampledf = ccjsonlower.head(50000)\n",
    "sampledf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dffdfdd",
   "metadata": {},
   "source": [
    "#### B. Remove all punctuation from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45b64887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the punctuation dictionary by using unicodedata\n",
    "import sys\n",
    "import unicodedata\n",
    "punctuation = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "                  if unicodedata.category(chr(i)).startswith('P'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "520b205b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:692: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value, self.name)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>well its great that he did something about tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>you are right mr president</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>you have given no input apart from saying i am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>i get the frustration but the reason they want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i am far from an expert on tpp and i would ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>0</td>\n",
       "      <td>gt its just too bad she sold her soul to fox n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>0</td>\n",
       "      <td>globalists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0</td>\n",
       "      <td>removed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0</td>\n",
       "      <td>i cant disagree that machines will take many j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>0</td>\n",
       "      <td>i disagree i think if child care were actually...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      con                                                txt\n",
       "0       0  well its great that he did something about tho...\n",
       "1       0                         you are right mr president\n",
       "2       0  you have given no input apart from saying i am...\n",
       "3       0  i get the frustration but the reason they want...\n",
       "4       0  i am far from an expert on tpp and i would ten...\n",
       "...    ..                                                ...\n",
       "49995   0  gt its just too bad she sold her soul to fox n...\n",
       "49996   0                                         globalists\n",
       "49997   0                                            removed\n",
       "49998   0  i cant disagree that machines will take many j...\n",
       "49999   0  i disagree i think if child care were actually...\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing punctuation from each row of dataframe's txt column\n",
    "for i in range(len(sampledf)) :\n",
    "    test = [string.translate(punctuation) for string in (sampledf.loc[i, \"txt\"])]\n",
    "    # coverting list to string\n",
    "    test1 = \"\".join(str(x) for x in test)\n",
    "    # updating the row values\n",
    "    sampledf.loc[i, [\"txt\"]] = test1\n",
    "# print dataframe after removing punctuations from txt column\n",
    "sampledf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822cb464",
   "metadata": {},
   "source": [
    "#### C. Remove stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb0cc4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db91a988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stop words\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c9dbc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:692: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value, self.name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['disagree', 'think', 'child', 'care', 'actually', 'important', 'issue', 'would', 'implemented', 'company', 'giii', 'actually', 'creates', 'distributes', 'fashion', 'line', 'offers', '0', 'paid', 'parental', 'leave', 'respectfully', 'think', 'youre', 'buying', 'optics', 'exact', 'response', 'designed', 'get']\n"
     ]
    }
   ],
   "source": [
    "# remove stop words from each row of dataframe's txt column\n",
    "for i in range(len(sampledf)) :\n",
    "    # tokenized each row of dataframe's txt column\n",
    "    test_token = word_tokenize(sampledf.loc[i, \"txt\"])\n",
    "    # remove stop words\n",
    "    rem_words = [word for word in test_token if word not in stop_words]\n",
    "    # coverting list to string\n",
    "    rem_words1 = \" \".join(str(x) for x in rem_words)\n",
    "    # writting back processed removed stop words to dataframe\n",
    "    # updating the row values for txt column\n",
    "    sampledf.loc[i, [\"txt\"]] = rem_words1\n",
    "# printing last rows of dataframe showing removed stop words\n",
    "print(rem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b014622d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>well great something beliefs office doubt trum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>right mr president</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>given input apart saying wrong argument clearly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>get frustration reason want way foundation com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>far expert tpp would tend agree lot problems u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>0</td>\n",
       "      <td>gt bad sold soul fox news really cant sympathe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>0</td>\n",
       "      <td>globalists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0</td>\n",
       "      <td>removed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0</td>\n",
       "      <td>cant disagree machines take many jobs embrace ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>0</td>\n",
       "      <td>disagree think child care actually important i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      con                                                txt\n",
       "0       0  well great something beliefs office doubt trum...\n",
       "1       0                                 right mr president\n",
       "2       0    given input apart saying wrong argument clearly\n",
       "3       0  get frustration reason want way foundation com...\n",
       "4       0  far expert tpp would tend agree lot problems u...\n",
       "...    ..                                                ...\n",
       "49995   0  gt bad sold soul fox news really cant sympathe...\n",
       "49996   0                                         globalists\n",
       "49997   0                                            removed\n",
       "49998   0  cant disagree machines take many jobs embrace ...\n",
       "49999   0  disagree think child care actually important i...\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print dataframe after updating the removed stop words to txt column\n",
    "sampledf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129319c8",
   "metadata": {},
   "source": [
    "#### D. Apply NLTK’s PorterStemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f37670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "# create stemmer\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59123851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:692: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value, self.name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['disagre', 'think', 'child', 'care', 'actual', 'import', 'issu', 'would', 'implement', 'compani', 'giii', 'actual', 'creat', 'distribut', 'fashion', 'line', 'offer', '0', 'paid', 'parent', 'leav', 'respect', 'think', 'your', 'buy', 'optic', 'exact', 'respons', 'design', 'get']\n"
     ]
    }
   ],
   "source": [
    "# apply stemmer to each row of dataframe's txt column\n",
    "for i in range(len(sampledf)) :\n",
    "    # tokenized each row of dataframe's txt column\n",
    "    test_token1 = word_tokenize(sampledf.loc[i, \"txt\"])\n",
    "    # apply stemmer\n",
    "    porter_words = [porter.stem(word) for word in test_token1]\n",
    "    # coverting list to string\n",
    "    porter_words1 = \" \".join(str(x) for x in porter_words)\n",
    "    # writting back processed removed stop words to dataframe\n",
    "    # updating the row values for txt column\n",
    "    sampledf.loc[i, [\"txt\"]] = porter_words1\n",
    "# printing last rows of dataframe showing removed stop words\n",
    "print(porter_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54050ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>well great someth belief offic doubt trump wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>right mr presid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>given input apart say wrong argument clearli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>get frustrat reason want way foundat complex p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>far expert tpp would tend agre lot problem und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>0</td>\n",
       "      <td>gt bad sold soul fox news realli cant sympathe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>0</td>\n",
       "      <td>globalist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0</td>\n",
       "      <td>remov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0</td>\n",
       "      <td>cant disagre machin take mani job embrac left ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>0</td>\n",
       "      <td>disagre think child care actual import issu wo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      con                                                txt\n",
       "0       0  well great someth belief offic doubt trump wou...\n",
       "1       0                                    right mr presid\n",
       "2       0       given input apart say wrong argument clearli\n",
       "3       0  get frustrat reason want way foundat complex p...\n",
       "4       0  far expert tpp would tend agre lot problem und...\n",
       "...    ..                                                ...\n",
       "49995   0  gt bad sold soul fox news realli cant sympathe...\n",
       "49996   0                                          globalist\n",
       "49997   0                                              remov\n",
       "49998   0  cant disagre machin take mani job embrac left ...\n",
       "49999   0  disagre think child care actual import issu wo...\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print dataframe after updating the applied stemmer to each row of dataframe's txt column\n",
    "sampledf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36390c6b",
   "metadata": {},
   "source": [
    "#### 2. Now that the data is pre-processed, you will apply three different techniques to get it into a usable form for model-building. Apply each of the following steps (individually) to the pre-processed data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e3fee3",
   "metadata": {},
   "source": [
    "#### A. Convert each text entry into a word-count vector (see sections 5.3 & 6.8 in the Machine Learning with Python Cookbook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c61ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24981c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = CountVectorizer()\n",
    "bag_of_words = count.fit_transform(sampledf['txt'].to_numpy())\n",
    "bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b7e76f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '0000001',\n",
       " '000005',\n",
       " '00001',\n",
       " '00003',\n",
       " '00005',\n",
       " '000079',\n",
       " '00009',\n",
       " '0003',\n",
       " '000327',\n",
       " '000844',\n",
       " '001',\n",
       " '0017',\n",
       " '00189',\n",
       " '002',\n",
       " '00282',\n",
       " '003',\n",
       " '0033',\n",
       " '00360',\n",
       " '005',\n",
       " '00598',\n",
       " '007',\n",
       " '00991',\n",
       " '01',\n",
       " '010',\n",
       " '01187',\n",
       " '01188',\n",
       " '01340',\n",
       " '01561',\n",
       " '016',\n",
       " '01604',\n",
       " '01825',\n",
       " '01c',\n",
       " '02',\n",
       " '02000',\n",
       " '02293',\n",
       " '02419',\n",
       " '025',\n",
       " '02561',\n",
       " '026',\n",
       " '0270',\n",
       " '03',\n",
       " '0304',\n",
       " '03069',\n",
       " '0311',\n",
       " '03167',\n",
       " '0351httpswwwthebalancecomusmcmos0351infantryassaultman3345320',\n",
       " '036',\n",
       " '03890',\n",
       " '04',\n",
       " '040',\n",
       " '04156',\n",
       " '04317',\n",
       " '04335fe51cbf',\n",
       " '04373',\n",
       " '04387',\n",
       " '043b605557dd',\n",
       " '04865',\n",
       " '0495b21268d',\n",
       " '04987',\n",
       " '05',\n",
       " '050',\n",
       " '05108',\n",
       " '0557',\n",
       " '05639',\n",
       " '057',\n",
       " '05871',\n",
       " '05953',\n",
       " '05961',\n",
       " '06',\n",
       " '06051',\n",
       " '06297',\n",
       " '06487',\n",
       " '06660',\n",
       " '06710',\n",
       " '06793',\n",
       " '07',\n",
       " '07004',\n",
       " '0708',\n",
       " '07434',\n",
       " '075',\n",
       " '077',\n",
       " '07766',\n",
       " '07787',\n",
       " '07b',\n",
       " '08',\n",
       " '08002000',\n",
       " '081',\n",
       " '08173',\n",
       " '08352',\n",
       " '084',\n",
       " '08653',\n",
       " '08694',\n",
       " '087',\n",
       " '09',\n",
       " '091',\n",
       " '0915',\n",
       " '092',\n",
       " '09220',\n",
       " '09474',\n",
       " '095',\n",
       " '09505',\n",
       " '09563',\n",
       " '09650',\n",
       " '097',\n",
       " '09891',\n",
       " '099',\n",
       " '0a3317d71b32',\n",
       " '0ae6aade2758',\n",
       " '0ahukewiiyimdkttqahulxomkhv9zaliqfgg9maqampurl',\n",
       " '0ahukewij8ps1xdzqahvrsvqkhrweaqqauibigb',\n",
       " '0ahukewilokkhudqahxigfqkhbnjbhkqyjcikqampei',\n",
       " '0ahukewiznlxndpqahurq1qkhxrgdvwqauiccgbampbiw',\n",
       " '0ahukewj8ryek9jqahvm5cykhtw4ccwq6aeisjagv',\n",
       " '0ahukewjfcpvm97qahvmdsakhfoed1yq6aeiijabv',\n",
       " '0ahukewjj1uj3lodqahvc8wmkhcihcdkqgqmigdaa',\n",
       " '0ahukewjt8aby39xqahujrvqkhsv3dzcqmwg8kbuwfqampiact',\n",
       " '0ampasvis',\n",
       " '0ampelect',\n",
       " '0ampfips',\n",
       " '0ampn',\n",
       " '0ampoffice',\n",
       " '0ampsession',\n",
       " '0ampyear',\n",
       " '0b4056ad8b78',\n",
       " '0bama',\n",
       " '0bozo',\n",
       " '0bwxugnzvhi',\n",
       " '0de1d1859c4',\n",
       " '0e54ab28c8e9',\n",
       " '0kpqvspwjog',\n",
       " '0life',\n",
       " '0m51',\n",
       " '0t7pnrelfdi',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '10000',\n",
       " '100000',\n",
       " '1000000',\n",
       " '10000000',\n",
       " '1000000000',\n",
       " '10000000000i',\n",
       " '10000000x',\n",
       " '10000karma',\n",
       " '10000man',\n",
       " '10001100',\n",
       " '10002000',\n",
       " '1000ish',\n",
       " '1000x',\n",
       " '1001',\n",
       " '10079ampadgroup',\n",
       " '100b',\n",
       " '100bn',\n",
       " '100bnyr',\n",
       " '100car',\n",
       " '100fold',\n",
       " '100ft',\n",
       " '100httpwwwelectionreturnspagovenrnew',\n",
       " '100k',\n",
       " '100k400k',\n",
       " '100k8',\n",
       " '100lb',\n",
       " '100m',\n",
       " '100mo',\n",
       " '100smo',\n",
       " '100th',\n",
       " '100x',\n",
       " '101',\n",
       " '1010',\n",
       " '1012',\n",
       " '101371journalpone0111629',\n",
       " '1013k',\n",
       " '1015',\n",
       " '1015165',\n",
       " '1016',\n",
       " '101720420',\n",
       " '101httpwwwconstitutionorgjl2ndtr05htm',\n",
       " '101st',\n",
       " '102',\n",
       " '1020',\n",
       " '1022',\n",
       " '1024',\n",
       " '1025',\n",
       " '103',\n",
       " '1030',\n",
       " '104',\n",
       " '104121',\n",
       " '1043ampcontext',\n",
       " '10468',\n",
       " '105',\n",
       " '1050',\n",
       " '105000',\n",
       " '1051511',\n",
       " '105274',\n",
       " '10537155',\n",
       " '1056000',\n",
       " '106',\n",
       " '1069',\n",
       " '1069208730',\n",
       " '107',\n",
       " '1070',\n",
       " '10704',\n",
       " '108',\n",
       " '1081',\n",
       " '1081459',\n",
       " '108myr',\n",
       " '109',\n",
       " '109355',\n",
       " '10996',\n",
       " '109m',\n",
       " '109th',\n",
       " '10ampisuri',\n",
       " '10d',\n",
       " '10ft',\n",
       " '10hr',\n",
       " '10ish',\n",
       " '10k',\n",
       " '10m',\n",
       " '10mm',\n",
       " '10red',\n",
       " '10s100',\n",
       " '10second',\n",
       " '10th',\n",
       " '10x',\n",
       " '10year',\n",
       " '10yearold',\n",
       " '11',\n",
       " '110',\n",
       " '1100',\n",
       " '11000',\n",
       " '110000',\n",
       " '11000year',\n",
       " '1100mo',\n",
       " '1108',\n",
       " '11082016ampcountyid',\n",
       " '110lb',\n",
       " '110m',\n",
       " '110th',\n",
       " '111',\n",
       " '1110',\n",
       " '1112',\n",
       " '11120',\n",
       " '11120312',\n",
       " '1115',\n",
       " '112',\n",
       " '11212015',\n",
       " '112th',\n",
       " '113',\n",
       " '113b',\n",
       " '113th',\n",
       " '114',\n",
       " '114000000',\n",
       " '1143',\n",
       " '1143611',\n",
       " '114m',\n",
       " '114th',\n",
       " '115',\n",
       " '1150',\n",
       " '115000',\n",
       " '1150hr',\n",
       " '115135',\n",
       " '11536504',\n",
       " '115487579',\n",
       " '11570808',\n",
       " '116',\n",
       " '11615',\n",
       " '117',\n",
       " '118',\n",
       " '118000',\n",
       " '118th',\n",
       " '119',\n",
       " '1199',\n",
       " '119day',\n",
       " '11am',\n",
       " '11ampareatypekeygdp',\n",
       " '11b',\n",
       " '11billion',\n",
       " '11hr',\n",
       " '11k',\n",
       " '11pm',\n",
       " '11t',\n",
       " '11th',\n",
       " '12',\n",
       " '120',\n",
       " '1200',\n",
       " '12000',\n",
       " '120000',\n",
       " '120000000',\n",
       " '12002c900',\n",
       " '1200mo',\n",
       " '12017',\n",
       " '12060amp7036',\n",
       " '121',\n",
       " '12116',\n",
       " '1212',\n",
       " '1215',\n",
       " '1216',\n",
       " '12167',\n",
       " '1218',\n",
       " '12184',\n",
       " '122',\n",
       " '1222016',\n",
       " '122577',\n",
       " '1228',\n",
       " '122m',\n",
       " '123',\n",
       " '123000',\n",
       " '1234',\n",
       " '12367541',\n",
       " '123960000',\n",
       " '124',\n",
       " '124301000',\n",
       " '124588000',\n",
       " '125',\n",
       " '125000',\n",
       " '1256myr',\n",
       " '125b',\n",
       " '125m',\n",
       " '126',\n",
       " '1262016',\n",
       " '1269',\n",
       " '127',\n",
       " '12702379',\n",
       " '12740571',\n",
       " '1277',\n",
       " '12773801',\n",
       " '127mm',\n",
       " '128',\n",
       " '12800000',\n",
       " '12830632',\n",
       " '12882135',\n",
       " '128k',\n",
       " '129',\n",
       " '12d',\n",
       " '12gaug',\n",
       " '12hour',\n",
       " '12hr',\n",
       " '12k',\n",
       " '12m',\n",
       " '12member',\n",
       " '12minut',\n",
       " '12mm',\n",
       " '12th',\n",
       " '12thsmallest',\n",
       " '12year',\n",
       " '12yearold',\n",
       " '13',\n",
       " '130',\n",
       " '1300',\n",
       " '130000',\n",
       " '13000word',\n",
       " '1300gt800',\n",
       " '130k',\n",
       " '130m',\n",
       " '131',\n",
       " '1314',\n",
       " '1317m',\n",
       " '132',\n",
       " '1320',\n",
       " '132000',\n",
       " '1323459',\n",
       " '132797',\n",
       " '1328302',\n",
       " '132lb',\n",
       " '133',\n",
       " '13329',\n",
       " '1339',\n",
       " '134',\n",
       " '134142',\n",
       " '1346',\n",
       " '1347',\n",
       " '135',\n",
       " '135266',\n",
       " '135m',\n",
       " '136',\n",
       " '136th',\n",
       " '137',\n",
       " '13700',\n",
       " '1375',\n",
       " '138',\n",
       " '1385000',\n",
       " '139',\n",
       " '1397ampbih',\n",
       " '139bn',\n",
       " '13billion',\n",
       " '13bn',\n",
       " '13d',\n",
       " '13hr',\n",
       " '13httpcdnphupicomsvemupiupi151140779163520141950eb4b89d02f6def7b31f9ae3f5de50fauxpasfewlaughingatpresidentsimpromptujokearchivejpg',\n",
       " '13httpswwwarchivesgovfederalregisterelectoralcollegekeydateshtml',\n",
       " '13k',\n",
       " '13m',\n",
       " '13ralli',\n",
       " '13rd',\n",
       " '13th',\n",
       " '14',\n",
       " '140',\n",
       " '1400',\n",
       " '14000',\n",
       " '140000',\n",
       " '140209',\n",
       " '1404054',\n",
       " '140800',\n",
       " '140charact',\n",
       " '140db',\n",
       " '141',\n",
       " '141000',\n",
       " '1414',\n",
       " '1415',\n",
       " '1416',\n",
       " '142',\n",
       " '14239',\n",
       " '142855995',\n",
       " '143915',\n",
       " '144',\n",
       " '145',\n",
       " '14500',\n",
       " '1459',\n",
       " '145x',\n",
       " '146',\n",
       " '1461',\n",
       " '147',\n",
       " '148',\n",
       " '1480885526ampsr',\n",
       " '1484',\n",
       " '1488er',\n",
       " '149k',\n",
       " '14b',\n",
       " '14billion',\n",
       " '14bn',\n",
       " '14m',\n",
       " '14th',\n",
       " '14yearold',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '15000',\n",
       " '150000',\n",
       " '15001',\n",
       " '15080',\n",
       " '150k',\n",
       " '15168',\n",
       " '15171',\n",
       " '1517ampbih',\n",
       " '1518',\n",
       " '151844',\n",
       " '152',\n",
       " '1520',\n",
       " '1520000',\n",
       " '1525',\n",
       " '152780',\n",
       " '1535',\n",
       " '153538',\n",
       " '154',\n",
       " '155',\n",
       " '156',\n",
       " '156k',\n",
       " '157',\n",
       " '158',\n",
       " '159',\n",
       " '1598',\n",
       " '15ampp',\n",
       " '15ampsmoothing',\n",
       " '15b',\n",
       " '15bn',\n",
       " '15d',\n",
       " '15hr',\n",
       " '15httpaicucdavisedupublicationsmocamocacurrentmoca09moca09chapter5pdf',\n",
       " '15ish',\n",
       " '15k',\n",
       " '15m',\n",
       " '15million',\n",
       " '15minut',\n",
       " '15second',\n",
       " '15th',\n",
       " '15year',\n",
       " '15yearold',\n",
       " '16',\n",
       " '160',\n",
       " '1600',\n",
       " '160000',\n",
       " '160000000',\n",
       " '1602',\n",
       " '160z',\n",
       " '1612136',\n",
       " '162219png',\n",
       " '1627700',\n",
       " '163',\n",
       " '1630',\n",
       " '163943',\n",
       " '164',\n",
       " '1642',\n",
       " '16432',\n",
       " '165',\n",
       " '1650',\n",
       " '16507',\n",
       " '1650k',\n",
       " '165800',\n",
       " '166',\n",
       " '167',\n",
       " '168',\n",
       " '1680',\n",
       " '16b',\n",
       " '16m',\n",
       " '16million',\n",
       " '16min',\n",
       " '16th',\n",
       " '16year',\n",
       " '16yearold',\n",
       " '17',\n",
       " '170',\n",
       " '1700',\n",
       " '17000',\n",
       " '170000',\n",
       " '170543',\n",
       " '1709',\n",
       " '170m',\n",
       " '170mm',\n",
       " '171',\n",
       " '171000',\n",
       " '1711',\n",
       " '173',\n",
       " '173351',\n",
       " '174',\n",
       " '175',\n",
       " '175db',\n",
       " '175mil',\n",
       " '176',\n",
       " '1760',\n",
       " '176465',\n",
       " '177',\n",
       " '1770',\n",
       " '1776',\n",
       " '17762016',\n",
       " '178',\n",
       " '1787',\n",
       " '1788',\n",
       " '179',\n",
       " '1790',\n",
       " '1792',\n",
       " '1796',\n",
       " '1799',\n",
       " '17990',\n",
       " '17d',\n",
       " '17mil',\n",
       " '17th',\n",
       " '17yearold',\n",
       " '18',\n",
       " '180',\n",
       " '1800',\n",
       " '18000',\n",
       " '180000',\n",
       " '1800ampyearend',\n",
       " '1801',\n",
       " '180180',\n",
       " '1803',\n",
       " '1804',\n",
       " '1804httpfivethirtyeightcomfeatureswarispeacefreedomisslaverytrumpwoninalandslid',\n",
       " '1808',\n",
       " '180k',\n",
       " '180º',\n",
       " '1812',\n",
       " '1816',\n",
       " '1820',\n",
       " '1821',\n",
       " '1824',\n",
       " '1825',\n",
       " '1828',\n",
       " '183',\n",
       " '1830',\n",
       " '1832',\n",
       " '1835',\n",
       " '1836',\n",
       " '184',\n",
       " '1840',\n",
       " '184566',\n",
       " '185',\n",
       " '1850',\n",
       " '1851',\n",
       " '1854304',\n",
       " '1856',\n",
       " '1856httpwwwpresidencyucsbeduwspid',\n",
       " '186',\n",
       " '1860',\n",
       " '1865',\n",
       " '1868',\n",
       " '1868516',\n",
       " '1870',\n",
       " '187000',\n",
       " '1875',\n",
       " '1876',\n",
       " '1877',\n",
       " '188000',\n",
       " '18801310',\n",
       " '1882',\n",
       " '18896800',\n",
       " '1890httpsbooksgooglecombooksid',\n",
       " '1890someth',\n",
       " '1892lb',\n",
       " '1893770',\n",
       " '1895',\n",
       " '1898',\n",
       " '18bn',\n",
       " '18th',\n",
       " '18yearold',\n",
       " '19',\n",
       " '190',\n",
       " '1900',\n",
       " '19000',\n",
       " '19021912',\n",
       " '1903',\n",
       " '1909',\n",
       " '190k',\n",
       " '1910',\n",
       " '1911',\n",
       " '19111930',\n",
       " '1912',\n",
       " '1913',\n",
       " '1914',\n",
       " '1916',\n",
       " '1917',\n",
       " '192',\n",
       " '1920',\n",
       " '192000',\n",
       " '19201932',\n",
       " '1920ampbih',\n",
       " '1920ampved',\n",
       " '1920both',\n",
       " '1920s30',\n",
       " '1923',\n",
       " '1924',\n",
       " '1927',\n",
       " '1929',\n",
       " '1929httpsenwikipediaorgwikireapportionmentactof1929',\n",
       " '193',\n",
       " '1930',\n",
       " '1930httpsenwikipediaorgwikiplantpatentactof1930',\n",
       " '1932',\n",
       " '19322010',\n",
       " '1933',\n",
       " '1934',\n",
       " '1935',\n",
       " '19371941',\n",
       " '19378102',\n",
       " '1938',\n",
       " '194',\n",
       " '1940',\n",
       " '19401941',\n",
       " '19401970',\n",
       " '1941',\n",
       " '194219',\n",
       " '1945',\n",
       " '194571',\n",
       " '1946',\n",
       " '1947',\n",
       " '1947across',\n",
       " '1947in',\n",
       " '1948',\n",
       " '1949',\n",
       " '19491415',\n",
       " '195',\n",
       " '1950',\n",
       " '1951',\n",
       " '1952',\n",
       " '19521954',\n",
       " '1953',\n",
       " '195369',\n",
       " '1955',\n",
       " '19552860',\n",
       " '1956',\n",
       " '1957',\n",
       " '1958',\n",
       " '1959',\n",
       " '195k',\n",
       " '1960',\n",
       " '1961',\n",
       " '1963',\n",
       " '1964',\n",
       " '1965',\n",
       " '19651127',\n",
       " '1966',\n",
       " '1967',\n",
       " '1968',\n",
       " '1969',\n",
       " '1969920',\n",
       " '1970',\n",
       " '197071',\n",
       " '1970sbut',\n",
       " '1971',\n",
       " '1972',\n",
       " '1973',\n",
       " '1974',\n",
       " '1975',\n",
       " '1976',\n",
       " '1977',\n",
       " '19774748',\n",
       " '1978',\n",
       " '1979',\n",
       " '19795791elector',\n",
       " '197m',\n",
       " '1980',\n",
       " '1981',\n",
       " '19811992',\n",
       " '19812010',\n",
       " '1982',\n",
       " '1983',\n",
       " '1984',\n",
       " '1984esqu',\n",
       " '1985',\n",
       " '1986',\n",
       " '1987',\n",
       " '198712',\n",
       " '1988',\n",
       " '1989',\n",
       " '199',\n",
       " '1990',\n",
       " '1990sera',\n",
       " '1991',\n",
       " '1992',\n",
       " '1993',\n",
       " '1994',\n",
       " '1994amptoyear',\n",
       " '1995',\n",
       " '199567',\n",
       " '1996',\n",
       " '1997',\n",
       " '1998',\n",
       " '1999',\n",
       " '19999999',\n",
       " '19billion',\n",
       " '19th',\n",
       " '1a',\n",
       " '1actual',\n",
       " '1amp',\n",
       " '1amp7001',\n",
       " '1amp7003',\n",
       " '1amp7004',\n",
       " '1amp7006',\n",
       " '1ampa',\n",
       " '1ampacrdn',\n",
       " '1ampdrill',\n",
       " '1ampil',\n",
       " '1ampisuri',\n",
       " '1ampmi',\n",
       " '1ampnrange',\n",
       " '1ampoi',\n",
       " '1ampunitofmeasurekeygdp',\n",
       " '1ampw',\n",
       " '1ampyeargdp',\n",
       " '1ampyeargdpend',\n",
       " '1b',\n",
       " '1bed1bath',\n",
       " '1billion',\n",
       " '1blue',\n",
       " '1bn',\n",
       " '1c1chbfenus718us718amptbm',\n",
       " '1caasueenus663us664ampq',\n",
       " '1call',\n",
       " '1child',\n",
       " '1clinton',\n",
       " '1conform',\n",
       " '1d',\n",
       " '1gdp',\n",
       " '1h08m30',\n",
       " '1http911courageorglinkeddocsglobeteaparty02jpg',\n",
       " '1httpdailycallercom20140214richliberalwomenpreferconservativemen',\n",
       " '1httpsenwikipediaorgwikiredstatesandbluest',\n",
       " '1httpsvoatcovpizzag',\n",
       " '1httpswwwredditcomrlawcomments57pcw2amygoodmanisfacingprisonforreportingonth',\n",
       " '1httpwwwglobalresearchcaamericacreatedalqaedaandtheisisterrorgroup54028812httpwwwglobalresearchcatwentysixthingsabouttheislamicstateisilthatobamadoesnotwantyoutoknowabout5414735',\n",
       " '1httpwwwglobalresearchcabreakingususednukesoniraqafghanistanatomicbombdroppedontoraboraexpert27972',\n",
       " '1httpwwwglobalresearchcachemtrailstheconsequencesoftoxicmetalsandchemicalaerosolsonhumanhealth19047',\n",
       " '1httpwwwglobalresearchcacopenhagenandglobalwarmingtenfactsandtenmythsonclimatechange164672httpwwwglobalresearchcaglobalwarmingmediapropaganda5364444',\n",
       " '1httpwwwglobalresearchcafluoridekillingussoftly53603972httpwwwglobalresearchcapoisonistreatmentthecampaigntofluoridateamerica315683httpwwwglobalresearchcathehealthimpactsoffluoridatedwatershakyscience5498885',\n",
       " '1httpwwwglobalresearchcageneticallymodifiedorganismsgmosplannedsterilizationofhumanity5511206',\n",
       " '1httpwwwglobalresearchcapariskillingsmedialiesunansweredquestionswasitafalseflag5424029',\n",
       " '1httpwwwpolitifactcomtruthometerstatements2015apr16hillaryclintonhillaryclintonflubsfamilysimmigrationhistori',\n",
       " '1httpwwwwnycorgstorybrooklynvoterpurgeageclintonsand',\n",
       " '1jkchgihptg',\n",
       " '1k',\n",
       " '1lt',\n",
       " '1m',\n",
       " '1m02',\n",
       " '1m33',\n",
       " '1m7',\n",
       " '1mday',\n",
       " '1million',\n",
       " '1mm',\n",
       " '1np5nv1bqxozyscr7yjs1ispwqa3d',\n",
       " '1nvdh0fmzr0',\n",
       " '1productdescriptionfeaturediv',\n",
       " '1s',\n",
       " '1someth',\n",
       " '1st',\n",
       " '1state',\n",
       " '1the',\n",
       " '1to1',\n",
       " '1v1',\n",
       " '1vote',\n",
       " '1wehab7irjaq',\n",
       " '1well',\n",
       " '1were',\n",
       " '1you',\n",
       " '1yr',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '20000',\n",
       " '200000',\n",
       " '2000000',\n",
       " '20000000',\n",
       " '200000httpiimgurcomjjsfcpepng',\n",
       " '20002006',\n",
       " '20002008ce',\n",
       " '2000but',\n",
       " '2000lt0',\n",
       " '2000mile',\n",
       " '2000milelong',\n",
       " '2001',\n",
       " '200109',\n",
       " '2001230',\n",
       " '2002',\n",
       " '200204',\n",
       " '20022006',\n",
       " '20023',\n",
       " '2003',\n",
       " '200300mo',\n",
       " '2003caa30903',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '20062008',\n",
       " '20062016',\n",
       " '2007',\n",
       " '20072012',\n",
       " '2008',\n",
       " '20082010',\n",
       " '20082016',\n",
       " '20089',\n",
       " '2008ampcorpus',\n",
       " '2008ampview',\n",
       " '2008httppeoplecomcelebritybarackobamaclaimsvictorybeforehugecrowdinchicago',\n",
       " '2008httpwwwsnopescompoliticsobamaairplaneasp',\n",
       " '2009',\n",
       " '20092011',\n",
       " '200amp7035',\n",
       " '200ampindustrykey',\n",
       " '200b',\n",
       " '200ft',\n",
       " '200k',\n",
       " '200kyear',\n",
       " '200m',\n",
       " '200month',\n",
       " '200x',\n",
       " '200year',\n",
       " '201',\n",
       " '2010',\n",
       " '20102016',\n",
       " '2010httpwwwtheatlanticcompoliticsarchive201003wouldgenpetraeusrunasademocrat37595',\n",
       " '2011',\n",
       " '20112013httpinsidersmorningstarcomtradingexecutivecompensationactiont',\n",
       " '2012',\n",
       " '20122015',\n",
       " '2012httpwwwgallupcompoll184784americansviewsoilgasindustryimprovingaspx',\n",
       " '2012httpwwwindependentcouknewsworldamericasdonaldtrumpstafferbrandonhallmichiganguiltyelectionfrauda7449046html',\n",
       " '2013',\n",
       " '20130128',\n",
       " '20132014',\n",
       " '201365',\n",
       " '2013httpswwwredditcomrpicscomments1tugnminevertrulyunderstoodhowmuchhealthcarein',\n",
       " '2014',\n",
       " '201484',\n",
       " '201487',\n",
       " '2014httpscdnimages1mediumcommax8001faotyacoypuhjiae3sjofapng',\n",
       " '2015',\n",
       " '201588',\n",
       " '2015amp7093',\n",
       " '2015ampstart',\n",
       " '2015httpsenwikipediaorgwikilistofusarmssalestotaiwan',\n",
       " '2015httpswwwyoutubecomwatchv',\n",
       " '2015q2ampyeargdpbegin',\n",
       " '2016',\n",
       " '20161201010840',\n",
       " '20161206',\n",
       " '20162020',\n",
       " '201623',\n",
       " '2016ampelect',\n",
       " '2016ampid',\n",
       " '2016ampoff',\n",
       " '2016hb6097',\n",
       " '2016httpbigstoryaporgarticle62acdd911e4d44a5b855acf25122bd22obamaadministrationconfirmsdoubledigitpremiumhik',\n",
       " '2016httpwwwnytimescominteractive20161028uspoliticsfbiletterhtmlr',\n",
       " '2016woohoo',\n",
       " '2017',\n",
       " '2018',\n",
       " '20182020',\n",
       " '2018httpsenwikipediaorgwikiunitedstatesgubernatorialelections2018',\n",
       " '2018i',\n",
       " '2019',\n",
       " '202',\n",
       " '2020',\n",
       " '2020httpiimgurcomnharum0jpg',\n",
       " '2020httpreddit5gq710',\n",
       " '2021',\n",
       " '2022',\n",
       " '2024',\n",
       " '2025',\n",
       " '2026',\n",
       " '2028',\n",
       " '2030',\n",
       " '2030k',\n",
       " '2032',\n",
       " '2036',\n",
       " '204',\n",
       " '2040',\n",
       " '2048',\n",
       " '2050',\n",
       " '206',\n",
       " '20666',\n",
       " '208',\n",
       " '20838',\n",
       " '2085287',\n",
       " '2086',\n",
       " '20868067',\n",
       " '2087',\n",
       " '208877',\n",
       " '209',\n",
       " '20hour',\n",
       " '20hr',\n",
       " '20ish',\n",
       " '20k',\n",
       " '20k30k',\n",
       " '20kyear',\n",
       " '20m',\n",
       " '20m18',\n",
       " '20m2',\n",
       " '20minut',\n",
       " '20someth',\n",
       " '20th',\n",
       " '20thcenturi',\n",
       " '20year',\n",
       " '20yearlow',\n",
       " '20yearshelflif',\n",
       " '21',\n",
       " '210',\n",
       " '2100',\n",
       " '21000',\n",
       " '210000',\n",
       " '21000year',\n",
       " '210khrhttpsenwikipediaorgwikiboeingvc25citenote4',\n",
       " '2110',\n",
       " '2117',\n",
       " '2129569',\n",
       " '213',\n",
       " '213897',\n",
       " '215',\n",
       " '215483',\n",
       " '216',\n",
       " '216739',\n",
       " '218',\n",
       " '219',\n",
       " '21ea67f47b74473525c0bbffaa97108dampoe',\n",
       " '21httpinjurypreventionbmjcomcontentearly20150609injuryprev2015041586fullpdfkeytype',\n",
       " '21m13',\n",
       " '21st',\n",
       " '21were',\n",
       " '22',\n",
       " '220',\n",
       " '2200',\n",
       " '22000',\n",
       " '2200amp7002',\n",
       " '221',\n",
       " '2226',\n",
       " '22300',\n",
       " '223000',\n",
       " '223553265',\n",
       " '224',\n",
       " '225',\n",
       " '2251',\n",
       " '225125831',\n",
       " '226',\n",
       " '22680',\n",
       " '22700',\n",
       " '228288',\n",
       " '229k',\n",
       " '22billstatus2222law2222sponsorship2222sponsored22',\n",
       " '22false',\n",
       " '22hr',\n",
       " '22httpwwwcnncom20161122usveteransstandforstandingrocktrnd',\n",
       " '22k',\n",
       " '22lr',\n",
       " '22mil',\n",
       " '22nd',\n",
       " '22wyden',\n",
       " '22x',\n",
       " '23',\n",
       " '230',\n",
       " '2300',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show features name\n",
    "count.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb9446e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0cba6fd",
   "metadata": {},
   "source": [
    "#### B. Convert each text entry into a part-of-speech tag vector (see section 6.7 in the Machine Learning with Python Cookbook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3a64aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7356c0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create list\n",
    "tagged_discussion = []\n",
    "# use pre-trained part of speech tagger\n",
    "for i in range(len(sampledf)) :\n",
    "    # tokenized each row of dataframe's txt column\n",
    "    test_token2 = word_tokenize(sampledf.loc[i, \"txt\"])\n",
    "    # apply stemmer\n",
    "    pos_words = pos_tag(test_token2)\n",
    "    # print(pos_words)\n",
    "    tagged_discussion.append([tag for words, tag in pos_words])\n",
    "    # coverting list to string\n",
    "    #pos_words1 = \" \".join(str(x) for x in pos_words)\n",
    "    # writting back processed removed stop words to dataframe\n",
    "    # updating the row values for txt column\n",
    "    #sampledf.loc[i, [\"txt\"]] = pos_words1\n",
    "# printing pos_words of last row in the dataframe\n",
    "print(pos_words)\n",
    "# printing the tag list of all rows of data frame\n",
    "print(tagged_discussion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0178d19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2d624b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use one-hot encoding to convert the tags into feature\n",
    "one_hot_multi = MultiLabelBinarizer()\n",
    "one_hot_multi.fit_transform(tagged_discussion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96250fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['$', \"''\", 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS',\n",
       "       'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP',\n",
       "       'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD',\n",
       "       'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', '``'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using classes_ we can see that each feature is a part of speech tag:\n",
    "# show feature name\n",
    "one_hot_multi.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5bf4fe",
   "metadata": {},
   "source": [
    "#### C. Convert each entry into a term frequency-inverse document frequency (tfidf) vector (see section 6.9 in the Machine Learning with Python Cookbook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d245c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "ftidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cac5874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tf-idf feature matrix\n",
    "feature_matrix = ftidf.fit_transform(sampledf['txt'].to_numpy())\n",
    "# show tf-idf feature matrix as dense matrix\n",
    "feature_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3986d1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'well': 32055,\n",
       " 'great': 12218,\n",
       " 'someth': 26970,\n",
       " 'belief': 4481,\n",
       " 'offic': 21074,\n",
       " 'doubt': 9154,\n",
       " 'trump': 29916,\n",
       " 'would': 32585,\n",
       " 'fight': 10820,\n",
       " 'un': 30498,\n",
       " 'im': 15969,\n",
       " 'realli': 24085,\n",
       " 'happi': 13430,\n",
       " 'obama': 20959,\n",
       " 'couldoh': 7449,\n",
       " 'wait': 31779,\n",
       " 'right': 24870,\n",
       " 'mr': 19849,\n",
       " 'presid': 23075,\n",
       " 'given': 11882,\n",
       " 'input': 16405,\n",
       " 'apart': 3441,\n",
       " 'say': 25556,\n",
       " 'wrong': 32641,\n",
       " 'argument': 3604,\n",
       " 'clearli': 6590,\n",
       " 'get': 11801,\n",
       " 'frustrat': 11434,\n",
       " 'reason': 24116,\n",
       " 'want': 31845,\n",
       " 'way': 31950,\n",
       " 'foundat': 11249,\n",
       " 'complex': 7004,\n",
       " 'problem': 23227,\n",
       " 'advanc': 2555,\n",
       " 'grade': 12153,\n",
       " 'decent': 8152,\n",
       " 'sat': 25509,\n",
       " 'type': 30187,\n",
       " 'test': 28919,\n",
       " 'math': 18863,\n",
       " 'dont': 9085,\n",
       " 'understand': 30637,\n",
       " 'lot': 18332,\n",
       " 'mathemat': 18864,\n",
       " 'answer': 3193,\n",
       " 'time': 29411,\n",
       " 'figur': 10823,\n",
       " 'common': 6945,\n",
       " 'sens': 25983,\n",
       " 'work': 32510,\n",
       " 'around': 3648,\n",
       " 'question': 23741,\n",
       " 'ill': 15934,\n",
       " 'prepar': 23046,\n",
       " 'take': 28640,\n",
       " 'colleg': 6830,\n",
       " 'level': 17908,\n",
       " 'cours': 7523,\n",
       " 'despit': 8483,\n",
       " 'averag': 3977,\n",
       " 'score': 25699,\n",
       " 'theyr': 29111,\n",
       " 'tri': 29798,\n",
       " 'bust': 5544,\n",
       " 'kid': 17357,\n",
       " 'ball': 4164,\n",
       " 'far': 10556,\n",
       " 'expert': 10327,\n",
       " 'tpp': 29667,\n",
       " 'tend': 28870,\n",
       " 'agre': 2693,\n",
       " 'push': 23629,\n",
       " 'creat': 7617,\n",
       " 'econom': 9526,\n",
       " 'bulwark': 5454,\n",
       " 'china': 6343,\n",
       " 'pacif': 21695,\n",
       " 'administr': 2529,\n",
       " 'recogn': 24188,\n",
       " 'increas': 16173,\n",
       " 'strength': 27698,\n",
       " 'matur': 18888,\n",
       " 'bellicos': 4490,\n",
       " 'see': 25833,\n",
       " 'south': 27085,\n",
       " 'sea': 25774,\n",
       " 'us': 31110,\n",
       " 'alli': 2867,\n",
       " 'penetr': 22094,\n",
       " 'mani': 18694,\n",
       " 'emerg': 9778,\n",
       " 'market': 18786,\n",
       " 'otherwis': 21440,\n",
       " 'natur': 20144,\n",
       " 'align': 2837,\n",
       " 'alway': 2954,\n",
       " 'thought': 29289,\n",
       " 'curiou': 7828,\n",
       " 'critiqu': 7676,\n",
       " 'hardli': 13455,\n",
       " 'saw': 25553,\n",
       " 'mention': 19135,\n",
       " 'track': 29674,\n",
       " 'record': 24202,\n",
       " 'someon': 26965,\n",
       " 'railroad': 23876,\n",
       " 'worker': 32517,\n",
       " 'corpor': 7369,\n",
       " 'interest': 16519,\n",
       " 'must': 19992,\n",
       " 'felt': 10731,\n",
       " 'huge': 15686,\n",
       " 'import': 16057,\n",
       " 'use': 31144,\n",
       " 'much': 19884,\n",
       " 'polit': 22676,\n",
       " 'capit': 5819,\n",
       " 'like': 18032,\n",
       " 'mayb': 18905,\n",
       " 'could': 7445,\n",
       " 'better': 4602,\n",
       " 'certainli': 6105,\n",
       " 'seem': 25841,\n",
       " 'yet': 32884,\n",
       " 'best': 4581,\n",
       " 'manag': 18663,\n",
       " 'vari': 31378,\n",
       " 'play': 22530,\n",
       " 'howev': 14215,\n",
       " 'strateg': 27673,\n",
       " 'throw': 29338,\n",
       " 'begin': 4452,\n",
       " 'signific': 26440,\n",
       " 'withdraw': 32423,\n",
       " 'foreign': 11160,\n",
       " 'definit': 8240,\n",
       " 'move': 19832,\n",
       " 'fill': 10834,\n",
       " 'void': 31623,\n",
       " 'may': 18903,\n",
       " 'look': 18279,\n",
       " 'end': 9847,\n",
       " 'western': 32123,\n",
       " 'hegemoni': 13652,\n",
       " 'elect': 9661,\n",
       " 'ascend': 3706,\n",
       " 'nationalist': 20121,\n",
       " 'movement': 19833,\n",
       " 'britain': 5294,\n",
       " 'franc': 11296,\n",
       " 'elsewher': 9729,\n",
       " 'what': 32149,\n",
       " 'sad': 25360,\n",
       " 'appear': 3486,\n",
       " 'entir': 9937,\n",
       " 'selfinflict': 25904,\n",
       " 'noth': 20766,\n",
       " 'forc': 11140,\n",
       " 'retract': 24719,\n",
       " 'develop': 8530,\n",
       " 'democraci': 8333,\n",
       " 'simpli': 26477,\n",
       " 'result': 24686,\n",
       " 'myopic': 20020,\n",
       " 'reaction': 24042,\n",
       " 'global': 11926,\n",
       " 'thank': 28950,\n",
       " 'feel': 10704,\n",
       " 'nowhttpsthenypostfileswordpresscom201611161109clintoncampelection01jpgquality': 20824,\n",
       " '90ampstrip': 2180,\n",
       " 'allampw': 2847,\n",
       " '642': 1862,\n",
       " 'lol': 18229,\n",
       " 'delet': 8287,\n",
       " 'cant': 5804,\n",
       " 'racist': 23827,\n",
       " 'black': 4786,\n",
       " 'friend': 11381,\n",
       " 'lololol': 18243,\n",
       " 'vast': 31388,\n",
       " 'major': 18604,\n",
       " 'misogynist': 19497,\n",
       " 'histori': 13972,\n",
       " 'werent': 32116,\n",
       " 'marri': 18803,\n",
       " 'women': 32470,\n",
       " 'nope': 20711,\n",
       " 'your': 32945,\n",
       " 'smoke': 26768,\n",
       " 'bad': 4109,\n",
       " 'lung': 18459,\n",
       " 'tobacco': 29502,\n",
       " 'carcinogen': 5847,\n",
       " 'plain': 22502,\n",
       " 'old': 21161,\n",
       " 'heavi': 13625,\n",
       " 'metal': 19190,\n",
       " 'mj': 19549,\n",
       " 'doesnt': 9008,\n",
       " 'industri': 16246,\n",
       " 'farm': 10575,\n",
       " 'ltthat': 18424,\n",
       " 'exactli': 10214,\n",
       " 'mean': 18982,\n",
       " 'especi': 10065,\n",
       " 'power': 22901,\n",
       " 'exist': 10283,\n",
       " 'awaygt': 4001,\n",
       " 'politician': 22686,\n",
       " 'one': 21207,\n",
       " 'clear': 6581,\n",
       " 'exampl': 10220,\n",
       " 'democrat': 8339,\n",
       " 'gay': 11687,\n",
       " 'marriag': 18804,\n",
       " 'hillari': 13892,\n",
       " 'evolv': 10204,\n",
       " 'respond': 24659,\n",
       " 'popular': 22769,\n",
       " 'opinion': 21308,\n",
       " 'societi': 26884,\n",
       " 'give': 11879,\n",
       " 'judg': 17139,\n",
       " 'show': 26348,\n",
       " 'mainstream': 18598,\n",
       " 'republican': 24579,\n",
       " 'away': 4000,\n",
       " 'arent': 3592,\n",
       " 'expand': 10304,\n",
       " 'youv': 32958,\n",
       " 'dupe': 9391,\n",
       " 'propaganda': 23364,\n",
       " 'believ': 4482,\n",
       " 'isnt': 16738,\n",
       " 'canada': 5757,\n",
       " 'uk': 30422,\n",
       " 'current': 7832,\n",
       " 'legal': 17808,\n",
       " 'mechan': 19013,\n",
       " 'state': 27437,\n",
       " 'seced': 25802,\n",
       " 'save': 25544,\n",
       " 'success': 28240,\n",
       " 'revolut': 24778,\n",
       " 'california': 5689,\n",
       " 'referendum': 24317,\n",
       " 'laugh': 17664,\n",
       " 'feder': 10687,\n",
       " 'court': 7526,\n",
       " 'meaningless': 18988,\n",
       " 'word': 32504,\n",
       " 'keep': 17278,\n",
       " 'fire': 10880,\n",
       " 'contain': 7233,\n",
       " 'he': 13568,\n",
       " 'anyth': 3417,\n",
       " 'peopl': 22119,\n",
       " 'stop': 27628,\n",
       " 'pretend': 23121,\n",
       " 'air': 2745,\n",
       " 'declar': 8172,\n",
       " 'dictat': 8613,\n",
       " 'life': 18006,\n",
       " 'honestli': 14103,\n",
       " 'upset': 31056,\n",
       " 'classic': 6555,\n",
       " 'case': 5934,\n",
       " 'govern': 12106,\n",
       " 'depart': 8402,\n",
       " 'interior': 16532,\n",
       " 'rat': 23967,\n",
       " 'ass': 3740,\n",
       " 'nativ': 20138,\n",
       " 'american': 2997,\n",
       " 'govt': 12128,\n",
       " 'treati': 29775,\n",
       " 'commun': 6953,\n",
       " 'organ': 21375,\n",
       " 'support': 28385,\n",
       " 'redistribut': 24260,\n",
       " 'wealth': 31976,\n",
       " 'money': 19664,\n",
       " 'lender': 17851,\n",
       " 'call': 5699,\n",
       " 'loser': 18324,\n",
       " 'cri': 7649,\n",
       " 'unattract': 30523,\n",
       " 'good': 12027,\n",
       " 'invok': 16626,\n",
       " 'httpswwwredditcomrpoliticscomments5eqcqnstanfordprofessordevelopstrumpconversiondaee57': 14972,\n",
       " 'gtone': 12850,\n",
       " 'characterist': 6192,\n",
       " 'abus': 2376,\n",
       " 'notic': 20778,\n",
       " 'disabl': 8724,\n",
       " 'attitud': 3869,\n",
       " 'client': 6613,\n",
       " 'resist': 24640,\n",
       " 'justif': 17190,\n",
       " 'feedback': 10699,\n",
       " 'loop': 18303,\n",
       " 'establish': 10077,\n",
       " 'control': 7283,\n",
       " 'justifi': 17191,\n",
       " 'acquiesc': 2454,\n",
       " 'there': 29069,\n",
       " 'behavior': 4460,\n",
       " 'wise': 32409,\n",
       " 'escap': 10054,\n",
       " 'hold': 14039,\n",
       " 'true': 29895,\n",
       " 'relationship': 24417,\n",
       " 'prison': 23191,\n",
       " 'polic': 22649,\n",
       " 'kind': 17380,\n",
       " 'authoritarian': 3929,\n",
       " 'regim': 24354,\n",
       " 'broader': 5305,\n",
       " 'messag': 19177,\n",
       " 'behav': 4459,\n",
       " 'first': 10902,\n",
       " 'place': 22491,\n",
       " 'gtrememb': 12912,\n",
       " 'next': 20377,\n",
       " 'four': 11257,\n",
       " 'year': 32818,\n",
       " 'hear': 13601,\n",
       " 'trope': 29868,\n",
       " 'appointe': 3501,\n",
       " 'that': 28959,\n",
       " 'boo': 5022,\n",
       " 'mike': 19314,\n",
       " 'penc': 22084,\n",
       " 'protest': 23440,\n",
       " 'street': 27690,\n",
       " 'explain': 10330,\n",
       " 'death': 8108,\n",
       " 'threat': 29308,\n",
       " 'got': 12081,\n",
       " 'think': 29144,\n",
       " 'poor': 22745,\n",
       " 'person': 22213,\n",
       " 'handout': 13393,\n",
       " 'need': 20217,\n",
       " 'submiss': 27808,\n",
       " 'automat': 3947,\n",
       " 'remov': 24482,\n",
       " 'either': 9641,\n",
       " 'link': 18090,\n",
       " 'shorten': 26315,\n",
       " 'redirector': 24258,\n",
       " 'rpolit': 25154,\n",
       " 'allow': 2881,\n",
       " 'shortern': 26318,\n",
       " 'user': 31157,\n",
       " 'abl': 2310,\n",
       " 'tell': 28847,\n",
       " 'go': 11956,\n",
       " 'click': 6606,\n",
       " 'encourag': 9843,\n",
       " 'resubmit': 24684,\n",
       " 'url': 31105,\n",
       " 'point': 22623,\n",
       " 'directli': 8715,\n",
       " 'content': 7241,\n",
       " 'submit': 28180,\n",
       " 'inform': 16311,\n",
       " 'found': 11248,\n",
       " 'herehttpswwwredditcomrpoliticswikifiltereddomainswikilinkshorteners2fredirect': 13743,\n",
       " 'bot': 5097,\n",
       " 'action': 2466,\n",
       " 'perform': 22166,\n",
       " 'pleas': 22545,\n",
       " 'contact': 7232,\n",
       " 'moder': 19599,\n",
       " 'subredditmessagecomposeto': 28192,\n",
       " 'concern': 7047,\n",
       " 'pretti': 23128,\n",
       " 'lay': 17711,\n",
       " 'man': 18660,\n",
       " 'term': 28895,\n",
       " 'suppli': 28379,\n",
       " 'side': 26411,\n",
       " 'discredit': 8771,\n",
       " 'anybodi': 3403,\n",
       " 'parti': 21860,\n",
       " 'fuck': 11449,\n",
       " 'moron': 19766,\n",
       " 'thing': 29126,\n",
       " 'made': 18539,\n",
       " 'name': 20070,\n",
       " 'read': 24047,\n",
       " 'pick': 22372,\n",
       " 'alreadi': 2918,\n",
       " 'past': 21922,\n",
       " 'fall': 10503,\n",
       " 'goddamn': 11973,\n",
       " 'funni': 11524,\n",
       " 'make': 18611,\n",
       " 'rsolips': 25178,\n",
       " 'fair': 10476,\n",
       " 'help': 13693,\n",
       " 'pay': 21980,\n",
       " 'crazi': 7608,\n",
       " 'spend': 27198,\n",
       " 'plan': 22505,\n",
       " 'guess': 13120,\n",
       " 'benefit': 4512,\n",
       " 'tax': 28739,\n",
       " 'though': 29286,\n",
       " 'crucifi': 7721,\n",
       " 'liber': 17951,\n",
       " 'univers': 30785,\n",
       " 'campus': 5753,\n",
       " 'exact': 10213,\n",
       " 'hardest': 13452,\n",
       " 'shut': 26385,\n",
       " 'conserv': 7172,\n",
       " 'speech': 27181,\n",
       " 'idea': 15851,\n",
       " 'honest': 14101,\n",
       " 'extrem': 10382,\n",
       " 'are': 3575,\n",
       " 'hav': 13527,\n",
       " 'ideologu': 15870,\n",
       " 'care': 5852,\n",
       " 'team': 28788,\n",
       " 'real': 24071,\n",
       " 'issu': 16754,\n",
       " 'oh': 21122,\n",
       " 'yeah': 32805,\n",
       " 'still': 27590,\n",
       " 'schedul': 25620,\n",
       " 'raid': 23873,\n",
       " 'dispensari': 8846,\n",
       " 'violat': 31563,\n",
       " 'law': 17682,\n",
       " 'consid': 7188,\n",
       " 'libertarian': 17968,\n",
       " 'cut': 7860,\n",
       " 'militari': 19336,\n",
       " 'dismantl': 8831,\n",
       " 'dea': 8066,\n",
       " 'big': 4655,\n",
       " 'ever': 10158,\n",
       " 'theyll': 29110,\n",
       " 'leav': 17767,\n",
       " 'high': 13836,\n",
       " 'dri': 9257,\n",
       " 'ask': 3727,\n",
       " 'snowden': 26841,\n",
       " 'brain': 5167,\n",
       " 'rtheredpil': 25204,\n",
       " 'guy': 13194,\n",
       " 'didnt': 8633,\n",
       " 'antitrump': 3371,\n",
       " 'come': 6874,\n",
       " 'said': 25391,\n",
       " 'stuff': 27759,\n",
       " 'suppos': 28396,\n",
       " 'intro': 16585,\n",
       " 'phone': 22334,\n",
       " 'knowingli': 17460,\n",
       " 'harbor': 13440,\n",
       " 'bin': 4706,\n",
       " 'laden': 17560,\n",
       " 'rescind': 24617,\n",
       " 'aid': 2734,\n",
       " 'suck': 28250,\n",
       " 'fat': 10612,\n",
       " 'dick': 8599,\n",
       " 'ugli': 30356,\n",
       " 'also': 2927,\n",
       " 'die': 8636,\n",
       " 'conway': 7310,\n",
       " 'queen': 23734,\n",
       " 'long': 18255,\n",
       " 'game': 11613,\n",
       " 'complet': 7001,\n",
       " 'elimin': 9710,\n",
       " 'public': 23552,\n",
       " 'educ': 9578,\n",
       " 'despis': 8482,\n",
       " 'fact': 10442,\n",
       " 'dollar': 9036,\n",
       " 'lower': 18362,\n",
       " 'class': 6549,\n",
       " 'turn': 30081,\n",
       " 'compet': 6989,\n",
       " 'privileg': 23204,\n",
       " 'posit': 22806,\n",
       " 'truli': 29909,\n",
       " 'incred': 16177,\n",
       " 'mental': 19133,\n",
       " 'gymnast': 13206,\n",
       " 'done': 9067,\n",
       " 'weird': 32041,\n",
       " 'stock': 27608,\n",
       " 'run': 25259,\n",
       " 'integr': 16491,\n",
       " 'refus': 24341,\n",
       " 'know': 17453,\n",
       " 'ahead': 2716,\n",
       " 'debat': 8114,\n",
       " 'leak': 17749,\n",
       " 'camp': 5737,\n",
       " 'wouldv': 32593,\n",
       " 'possibl': 22815,\n",
       " 'reduc': 24273,\n",
       " 'everyon': 10175,\n",
       " 'cheer': 6258,\n",
       " 'settl': 26064,\n",
       " 'gt': 12342,\n",
       " 'hell': 13674,\n",
       " 'she': 26156,\n",
       " 'less': 17879,\n",
       " 'corrupt': 7400,\n",
       " 'almost': 2904,\n",
       " 'zero': 33010,\n",
       " 'substanc': 28211,\n",
       " '100': 136,\n",
       " 'fear': 10666,\n",
       " 'monger': 19675,\n",
       " 'rhetor': 24822,\n",
       " 'jesu': 16981,\n",
       " 'notch': 20759,\n",
       " 'wikileak': 32313,\n",
       " 'undeni': 30595,\n",
       " 'proof': 23357,\n",
       " 'cabinet': 5642,\n",
       " 'assembl': 3757,\n",
       " 'citigroup': 6501,\n",
       " 'execut': 10259,\n",
       " 'even': 10150,\n",
       " '2008': 837,\n",
       " 'safe': 25375,\n",
       " 'space': 27116,\n",
       " 'ff': 10779,\n",
       " 'topic': 29584,\n",
       " 'statement': 27453,\n",
       " 'gtto': 13022,\n",
       " 'explicitli': 10336,\n",
       " 'focu': 11076,\n",
       " 'follow': 11093,\n",
       " 'servic': 26051,\n",
       " 'policymak': 22669,\n",
       " 'privat': 23198,\n",
       " 'stori': 27636,\n",
       " 'demonstr': 8363,\n",
       " 'lobbi': 18187,\n",
       " 'candidaci': 5770,\n",
       " 'fund': 11508,\n",
       " 'group': 12305,\n",
       " 'donor': 9081,\n",
       " 'gtthi': 13011,\n",
       " 'includ': 16140,\n",
       " 'nonpolit': 20638,\n",
       " 'ex': 10210,\n",
       " 'barack': 4243,\n",
       " 'paint': 21728,\n",
       " 'pictur': 22381,\n",
       " 'rel': 24413,\n",
       " 'associ': 3780,\n",
       " 'dian': 8585,\n",
       " 'feinstein': 10716,\n",
       " 'father': 10621,\n",
       " 'predat': 22981,\n",
       " 'attempt': 3859,\n",
       " 'murder': 19955,\n",
       " 'arnold': 3643,\n",
       " 'schwarzenegg': 25670,\n",
       " 'intern': 16540,\n",
       " 'unless': 30800,\n",
       " 'discuss': 8779,\n",
       " 'focus': 11077,\n",
       " 'implic': 16051,\n",
       " 'tension': 28882,\n",
       " 'greec': 12229,\n",
       " 'itali': 16775,\n",
       " 'rise': 24935,\n",
       " 'cost': 7418,\n",
       " 'feta': 10761,\n",
       " 'chees': 6261,\n",
       " 'media': 19019,\n",
       " 'explicit': 10335,\n",
       " 'connot': 7152,\n",
       " 'cnn': 6701,\n",
       " 'wolf': 32455,\n",
       " 'blitzer': 4860,\n",
       " 'simpl': 26471,\n",
       " 'straight': 27651,\n",
       " 'lie': 17997,\n",
       " 'era': 10014,\n",
       " 'order': 21362,\n",
       " 'behind': 4465,\n",
       " 'never': 20314,\n",
       " 'id': 15847,\n",
       " 'day': 8037,\n",
       " 'account': 2419,\n",
       " 'massiv': 18841,\n",
       " 'growth': 12327,\n",
       " 'came': 5724,\n",
       " 'tenur': 28889,\n",
       " 'gtpolit': 12881,\n",
       " 'correct': 7388,\n",
       " 'invent': 16604,\n",
       " 'phantom': 22293,\n",
       " 'enemi': 9871,\n",
       " 'let': 17898,\n",
       " 'trigger': 29830,\n",
       " 'incid': 16132,\n",
       " 'havent': 13534,\n",
       " 'happen': 13424,\n",
       " 'john': 17076,\n",
       " 'stuart': 27740,\n",
       " 'mill': 19350,\n",
       " 'talk': 28660,\n",
       " 'back': 4055,\n",
       " '19th': 732,\n",
       " 'centuri': 6092,\n",
       " 'pakistan': 21733,\n",
       " 'compliment': 7011,\n",
       " 'liter': 18128,\n",
       " 'everi': 10165,\n",
       " 'sentenc': 26001,\n",
       " 'headlin': 13577,\n",
       " 'joke': 17090,\n",
       " 'wors': 32561,\n",
       " 'thedonald': 29001,\n",
       " 'meme': 19103,\n",
       " 'conspiraci': 7200,\n",
       " 'theori': 29054,\n",
       " 'pure': 23609,\n",
       " 'nonsens': 20666,\n",
       " '247': 1036,\n",
       " 'tic': 29377,\n",
       " 'tac': 28606,\n",
       " 'skittl': 26594,\n",
       " 'recount': 24207,\n",
       " 'michigan': 19248,\n",
       " 'pointless': 22627,\n",
       " 'yah': 32773,\n",
       " 'actual': 2482,\n",
       " 'outsourc': 21527,\n",
       " 'job': 17046,\n",
       " '1000': 137,\n",
       " 'send': 25974,\n",
       " '1100': 230,\n",
       " 'countri': 7495,\n",
       " 'annoy': 3175,\n",
       " 'sinc': 26488,\n",
       " 'neg': 20229,\n",
       " 'might': 19305,\n",
       " 'selfidentifi': 25898,\n",
       " 'sjw': 26559,\n",
       " 'internet': 16545,\n",
       " 'full': 11489,\n",
       " 'bullshit': 5449,\n",
       " 'youtub': 32955,\n",
       " 'enjoy': 9898,\n",
       " 'clown': 6676,\n",
       " 'fiesta': 10812,\n",
       " 'shit': 26233,\n",
       " 'awkwardli': 4008,\n",
       " 'view': 31529,\n",
       " 'social': 26872,\n",
       " 'eg': 9608,\n",
       " 'gun': 13155,\n",
       " 'appeal': 3483,\n",
       " 'voter': 31662,\n",
       " 'hint': 13945,\n",
       " 'learn': 17757,\n",
       " 'love': 18351,\n",
       " 'revolv': 24783,\n",
       " 'breachload': 5206,\n",
       " 'rifl': 24865,\n",
       " 'shotgun': 26334,\n",
       " 'walmart': 31828,\n",
       " 'situat': 26545,\n",
       " 'locat': 18197,\n",
       " 'town': 29651,\n",
       " 'infrastructur': 16326,\n",
       " 'build': 5418,\n",
       " 'road': 25000,\n",
       " 'sure': 28424,\n",
       " 'store': 27634,\n",
       " 'connect': 7147,\n",
       " 'water': 31930,\n",
       " 'sewer': 26080,\n",
       " 'electr': 9684,\n",
       " 'sale': 25413,\n",
       " 'revenu': 24755,\n",
       " 'enough': 9904,\n",
       " 'bond': 5003,\n",
       " 'took': 29565,\n",
       " 'httpwwwstrongtownsorgthegrowthponzischem': 15570,\n",
       " 'miss': 19510,\n",
       " 'second': 25805,\n",
       " 'welfar': 32052,\n",
       " 'taxpay': 28759,\n",
       " 'put': 23643,\n",
       " 'disson': 8893,\n",
       " 'shown': 26354,\n",
       " 'theoret': 29053,\n",
       " 'scenario': 25610,\n",
       " 'white': 32228,\n",
       " 'pride': 23155,\n",
       " 'asshol': 3770,\n",
       " 'okay': 21150,\n",
       " 'adopt': 2541,\n",
       " 'fail': 10470,\n",
       " 'substanti': 28215,\n",
       " 'differ': 8649,\n",
       " 'two': 30158,\n",
       " 'stupid': 27771,\n",
       " 'broken': 5315,\n",
       " 'famili': 10527,\n",
       " 'low': 18360,\n",
       " 'drug': 9291,\n",
       " 'agenc': 2659,\n",
       " 'statist': 27494,\n",
       " 'uwhyyouareverywrong': 31295,\n",
       " 'apropo': 3525,\n",
       " 'smackdown': 26719,\n",
       " 'udamean1': 30286,\n",
       " 'clinton': 6631,\n",
       " 'daughter': 8025,\n",
       " 'mother': 19802,\n",
       " 'jone': 17099,\n",
       " 'writer': 32636,\n",
       " 'rag': 23866,\n",
       " 'accus': 2431,\n",
       " 'news': 20338,\n",
       " 'stretch': 27703,\n",
       " 'david': 8030,\n",
       " 'corn': 7355,\n",
       " 'pussi': 23635,\n",
       " 'access': 2397,\n",
       " '17': 511,\n",
       " 'report': 24543,\n",
       " 'employe': 9813,\n",
       " 'bill': 4686,\n",
       " 'countless': 7493,\n",
       " 'sexual': 26086,\n",
       " 'improprieti': 16080,\n",
       " 'retort': 24717,\n",
       " 'girl': 11868,\n",
       " 'dad': 7920,\n",
       " 'probabl': 23216,\n",
       " 'told': 29529,\n",
       " 'write': 32632,\n",
       " '15': 435,\n",
       " 'total': 29617,\n",
       " 'agricultur': 2703,\n",
       " 'product': 23263,\n",
       " 'ship': 26221,\n",
       " 'rural': 25280,\n",
       " 'area': 3577,\n",
       " 'farmer': 10577,\n",
       " 'vote': 31650,\n",
       " 'maga': 18556,\n",
       " 'copout': 7335,\n",
       " 'scientif': 25679,\n",
       " 'evid': 10188,\n",
       " 'precursor': 22980,\n",
       " 'medicin': 19047,\n",
       " 'bigli': 4668,\n",
       " 'dumb': 9358,\n",
       " 'nah': 20057,\n",
       " 'ha': 13223,\n",
       " 'goodman': 12036,\n",
       " 'upvot': 31073,\n",
       " 'uniron': 30779,\n",
       " 'unqualifi': 30868,\n",
       " 'investig': 16610,\n",
       " 'treason': 29768,\n",
       " 'johnson': 17079,\n",
       " 'option': 21341,\n",
       " 'jill': 17019,\n",
       " 'stein': 27533,\n",
       " 'respect': 24653,\n",
       " 'candid': 5769,\n",
       " 'deserv': 8467,\n",
       " 'els': 9726,\n",
       " 'withdrawn': 32424,\n",
       " 'left': 17785,\n",
       " 'ideal': 15854,\n",
       " 'third': 29159,\n",
       " 'world': 32546,\n",
       " 'counti': 7487,\n",
       " 'easi': 9481,\n",
       " 'fix': 10927,\n",
       " 'beyond': 4618,\n",
       " 'remind': 24473,\n",
       " 'subreddit': 28191,\n",
       " 'civil': 6511,\n",
       " 'discussionhttpswwwredditcomrpoliticswikirulesandregswikipleasebecivil': 8781,\n",
       " 'troll': 29858,\n",
       " 'children': 6327,\n",
       " 'clever': 6602,\n",
       " 'attack': 3851,\n",
       " 'whether': 32196,\n",
       " 'implicit': 16052,\n",
       " 'permittedhttpswwwredditcomrpoliticswikirulesandregswikinopersonalattack': 22194,\n",
       " 'shill': 26209,\n",
       " 'proper': 23375,\n",
       " 'conduct': 7084,\n",
       " 'modmail': 19614,\n",
       " 'gener': 11728,\n",
       " 'jerk': 16968,\n",
       " 'bait': 4144,\n",
       " 'hate': 13514,\n",
       " 'etc': 10090,\n",
       " 'downvot': 9196,\n",
       " 'comment': 6900,\n",
       " 'disagre': 8729,\n",
       " 'will': 32335,\n",
       " 'qualiti': 23705,\n",
       " 'held': 13670,\n",
       " 'incivil': 16137,\n",
       " 'escal': 10053,\n",
       " 'ban': 4186,\n",
       " 'uncivil': 30557,\n",
       " 'repli': 24536,\n",
       " 'sourc': 27049,\n",
       " 'eh': 9625,\n",
       " 'spell': 27191,\n",
       " 'layman': 17714,\n",
       " 'mislead': 19491,\n",
       " 'caricatur': 5874,\n",
       " 'reflect': 24325,\n",
       " 'realiti': 24083,\n",
       " 'supplysid': 28383,\n",
       " 'policyhttpswwwyoutubecomwatchv': 22667,\n",
       " 'rcbelgaowu': 24016,\n",
       " 'intent': 16504,\n",
       " 'part': 21855,\n",
       " 'httpsenwikipediaorgwikidemocratpartyepithet': 14608,\n",
       " 'hahahahaha': 13270,\n",
       " 'crack': 7571,\n",
       " 'whole': 32252,\n",
       " 'bigot': 4672,\n",
       " 'equat': 9998,\n",
       " 'along': 2908,\n",
       " 'express': 10351,\n",
       " 'empathi': 9802,\n",
       " 'evil': 10195,\n",
       " 'anyon': 3415,\n",
       " 'caught': 5996,\n",
       " 'rape': 23942,\n",
       " 'child': 6315,\n",
       " 'strangl': 27667,\n",
       " 'puppi': 23604,\n",
       " 'moon': 19726,\n",
       " 'walk': 31810,\n",
       " 'immigr': 16008,\n",
       " 'isi': 16714,\n",
       " 'idiot': 15880,\n",
       " 'patriot': 21957,\n",
       " 'muh': 19905,\n",
       " 'fascism': 10592,\n",
       " 'lib': 17947,\n",
       " 'huh': 15692,\n",
       " 'repeal': 24520,\n",
       " 'small': 26721,\n",
       " 'token': 29525,\n",
       " 'remain': 24459,\n",
       " 'continu': 7260,\n",
       " 'disappoint': 8734,\n",
       " 'afraid': 2623,\n",
       " 'special': 27159,\n",
       " 'damn': 7959,\n",
       " 'shame': 26121,\n",
       " 'wall': 31816,\n",
       " 'vs': 31715,\n",
       " 'without': 32431,\n",
       " 'ad': 2491,\n",
       " 'number': 20885,\n",
       " 'comfort': 6887,\n",
       " 'similar': 26465,\n",
       " 'janki': 16905,\n",
       " 'written': 32639,\n",
       " '26': 1075,\n",
       " '20': 806,\n",
       " '10': 135,\n",
       " '30': 1212,\n",
       " '13': 348,\n",
       " '43': 1505,\n",
       " 'new': 20322,\n",
       " 'subtract': 28227,\n",
       " 'break': 5212,\n",
       " '1s': 793,\n",
       " 'togeth': 29520,\n",
       " 'combin': 6869,\n",
       " 'add': 2500,\n",
       " 'harder': 13450,\n",
       " 'least': 17764,\n",
       " 'head': 13569,\n",
       " 'assum': 3786,\n",
       " 'admit': 2534,\n",
       " 'feloni': 10729,\n",
       " 'gave': 11681,\n",
       " 'classifi': 6558,\n",
       " 'materi': 18860,\n",
       " 'biograph': 4719,\n",
       " 'qualifi': 23702,\n",
       " 'handl': 13389,\n",
       " 'drop': 9280,\n",
       " 'tall': 28663,\n",
       " 'gtif': 12705,\n",
       " 'pot': 22872,\n",
       " 'set': 26061,\n",
       " 'decad': 8139,\n",
       " 'marijuana': 18771,\n",
       " 'littl': 18141,\n",
       " 'bit': 4752,\n",
       " 'exagger': 10216,\n",
       " 'hmm': 14000,\n",
       " 'last': 17639,\n",
       " 'rememb': 24468,\n",
       " 'video': 31517,\n",
       " 'quit': 23769,\n",
       " 'idk': 15882,\n",
       " 'sound': 27042,\n",
       " 'nearli': 20196,\n",
       " 'deal': 8087,\n",
       " 'describ': 8456,\n",
       " 'hard': 13442,\n",
       " 'alcohol': 2805,\n",
       " 'danger': 7973,\n",
       " 'pack': 21698,\n",
       " 'stan': 27394,\n",
       " 'fabul': 10420,\n",
       " 'gold': 11999,\n",
       " 'furnitur': 11537,\n",
       " 'whitehous': 32233,\n",
       " 'makeshttpsenmwikipediaorgwikiinternationallaw': 18617,\n",
       " 'watch': 31922,\n",
       " 'everyth': 10179,\n",
       " 'constitu': 7213,\n",
       " 'everywher': 10183,\n",
       " 'incub': 16182,\n",
       " 'cmon': 6695,\n",
       " 'cheat': 6238,\n",
       " 'incas': 16117,\n",
       " 'hire': 13961,\n",
       " 'kindheart': 17384,\n",
       " 'intellig': 16497,\n",
       " 'woman': 32465,\n",
       " 'wrangl': 32611,\n",
       " 'whackitud': 32141,\n",
       " 'lost': 18329,\n",
       " 'lose': 18322,\n",
       " 'wasnt': 31907,\n",
       " 'worthi': 32574,\n",
       " 'talent': 28656,\n",
       " 'shitton': 26275,\n",
       " 'unfortun': 30721,\n",
       " 'tangl': 28692,\n",
       " 'spin': 27224,\n",
       " 'longer': 18259,\n",
       " 'tie': 29386,\n",
       " 'gotten': 12091,\n",
       " 'defens': 8226,\n",
       " 'vocal': 31614,\n",
       " 'nice': 20391,\n",
       " 'anymor': 3411,\n",
       " 'levelhead': 17909,\n",
       " 'victim': 31509,\n",
       " 'stay': 27509,\n",
       " 'inner': 16389,\n",
       " 'circl': 6474,\n",
       " 'reput': 24603,\n",
       " 'suffer': 28266,\n",
       " 'sadli': 25369,\n",
       " 'uh': 30362,\n",
       " 'fyi': 11561,\n",
       " 'brought': 5333,\n",
       " 'race': 23805,\n",
       " 'guilti': 13137,\n",
       " 'live': 18147,\n",
       " 'echo': 9514,\n",
       " 'chamber': 6142,\n",
       " 'somewhat': 26978,\n",
       " 'scienc': 25674,\n",
       " 'standard': 27398,\n",
       " 'practic': 22923,\n",
       " 'texa': 28932,\n",
       " 'biolog': 4722,\n",
       " 'york': 32918,\n",
       " 'wiggl': 32308,\n",
       " 'room': 25089,\n",
       " 'cram': 7581,\n",
       " 'curriculum': 7835,\n",
       " 'needless': 20222,\n",
       " 'confus': 7115,\n",
       " 'error': 10045,\n",
       " 'find': 10854,\n",
       " 'effect': 9597,\n",
       " ...}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show tf-idf feature names\n",
    "ftidf.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b53b43b",
   "metadata": {},
   "source": [
    "#### Follow-Up Question\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6d88cc",
   "metadata": {},
   "source": [
    "\n",
    "#### For the three techniques in problem (2) above, give an example where each would be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6685080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Tagging Parts of Speech\n",
    "#### POS tagging is very key in text-to-speech systems, information extraction, machine translation, and word sense disambiguation.\n",
    "#### It is useful in labeling named entities like people or places.\n",
    "#### example, \n",
    "#### let’s say we have a language model that understands the English language\n",
    "#### How can our model tell the difference between the word “address” used in different contexts?\n",
    "#### \"I would like to address the public on this issue\"\n",
    "#### \"We need your shipping address\"\n",
    "#### \"address\" in the first sentence is a Verb \n",
    "#### whereas \"address\" in the second sentence is a Noun \n",
    "#### Identifying the part of speech of the various words in a sentence can help in defining its meanings.\n",
    "#### In the example above, if the word “address” in the first sentence was a Noun, the sentence would have an entirely different meaning. Its part of speech is dependent on the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a5c1aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Encoding Text as BAG of Words\n",
    "#### Bag of words (BOW) is a technique to extract features from the text for Natural Language Processing.\n",
    "#### It’s an algorithm that transforms the text into fixed-length vectors. This is possible by counting the number of times the word is present in a document in a document.\n",
    "#### The word occurrences allow to compare different documents and evaluate their similarities for applications, such as search, document classification, and topic modeling..\n",
    "#### example, \n",
    "#### We could be interested in analyzing the reviews about Game of Thrones:\n",
    "#### Review 1: Game of Thrones is an amazing tv series!\n",
    "#### Review 2: Game of Thrones is the best tv series!\n",
    "#### Review 3: Game of Thrones is so great\n",
    "#### we only considered only unigram (single words) or bigrams(couples of words), but also trigrams can be taken into account to extract features. Stop words can be removed too as we saw, but there are still some disadvantages. \n",
    "#### The order and the meaning of the words are lost using this method.\n",
    "#### For this reason, other approaches are preferred to extract features from the text, like TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a709656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Weighted Word Importance\n",
    "#### here we are comparing the frequence of words in a document (a tweet, moview review speech transcripyt) \n",
    "#### with the frequency of words in all other documents using term frequency-inverse document frequency\n",
    "#### example\n",
    "#### TF*IDF is used by search engines to better understand the content that is undervalued. For example, when you search for “Coke” on Google, \n",
    "#### Google may use TF*IDF to figure out if a page titled “COKE” is about:\n",
    "#### a) Coca-Cola. b) Cocaine. c) A solid, carbon-rich residue derived from the distillation of crude oil.d) A county in Texas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
